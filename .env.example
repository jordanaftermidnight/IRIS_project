# IRIS Environment Configuration Template
# Copy this file to .env and configure your settings
# 
# ⚠️  SECURITY WARNING: Never commit .env files with real API keys!
# ⚠️  Add .env to your .gitignore if not already present

# =============================================================================
# AI PROVIDER API KEYS (Optional - Ollama works without any keys)
# =============================================================================

# OpenAI (GPT-4, o1-preview) - https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-api-key-here

# Google Gemini (Multimodal AI) - https://makersuite.google.com/app/apikey  
# GEMINI_API_KEY=your-gemini-api-key-here

# Groq (Ultra-fast inference) - https://console.groq.com/keys
# GROQ_API_KEY=gsk-your-groq-api-key-here

# Anthropic Claude (Advanced reasoning) - https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-claude-api-key-here

# =============================================================================
# IRIS SERVER CONFIGURATION
# =============================================================================

# Server binding (security: use 127.0.0.1 for localhost-only)
IRIS_HOST=127.0.0.1
IRIS_PORT=3001

# Development/Production mode
NODE_ENV=development

# Request rate limiting (requests per window)
IRIS_RATE_LIMIT_MAX=100
IRIS_RATE_LIMIT_WINDOW=900000

# Cache settings
IRIS_CACHE_TTL_MINUTES=5
IRIS_CACHE_MAX_ITEMS=50

# =============================================================================
# SECURITY SETTINGS
# =============================================================================

# Maximum request body size (prevents large payload attacks)
IRIS_MAX_REQUEST_SIZE=1mb

# Enable/disable request logging (disable in production for privacy)
IRIS_ENABLE_LOGGING=false

# Allowed origins for CORS (comma-separated)
IRIS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# =============================================================================
# LOCAL AI CONFIGURATION
# =============================================================================

# Ollama server URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Preferred local model (will auto-detect if not available)
OLLAMA_PREFERRED_MODEL=mistral:7b

# =============================================================================
# SECURITY CHECKLIST
# =============================================================================
# ✅ Never commit this file with real API keys
# ✅ Use strong, unique API keys for each service  
# ✅ Rotate API keys regularly
# ✅ Monitor API usage for unusual activity
# ✅ Use localhost binding for local development
# ✅ Keep dependencies updated (run: npm audit fix)
# ✅ Review access logs regularly
# =============================================================================